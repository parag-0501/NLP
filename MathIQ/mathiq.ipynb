{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8105748,
          "sourceType": "datasetVersion",
          "datasetId": 4787422
        }
      ],
      "dockerImageVersionId": 30664,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x # enable TF 2.x in Colab\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T07:58:32.511116Z",
          "iopub.execute_input": "2024-04-13T07:58:32.512156Z",
          "iopub.status.idle": "2024-04-13T07:58:34.088231Z",
          "shell.execute_reply.started": "2024-04-13T07:58:32.512118Z",
          "shell.execute_reply": "2024-04-13T07:58:34.086856Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kov_b8anhY5",
        "outputId": "4b06f9b6-6f3c-43b9-cde7-46e23a761c1b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T07:58:41.609361Z",
          "iopub.execute_input": "2024-04-13T07:58:41.609773Z",
          "iopub.status.idle": "2024-04-13T07:58:41.618500Z",
          "shell.execute_reply.started": "2024-04-13T07:58:41.609741Z",
          "shell.execute_reply": "2024-04-13T07:58:41.617137Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wYWi5f6unhY9",
        "outputId": "3bf99a9b-f82c-42de-9656-c5a95f68a014"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov9l2UQ4pBzh",
        "outputId": "c2cd9b44-d14a-49f4-feed-8ab260831e57"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = '/content/drive/MyDrive/NLP Mandate/MathIQ_Dataset - Sheet1.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(csv_file_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T07:58:53.355077Z",
          "iopub.execute_input": "2024-04-13T07:58:53.356161Z",
          "iopub.status.idle": "2024-04-13T07:58:53.510848Z",
          "shell.execute_reply.started": "2024-04-13T07:58:53.356122Z",
          "shell.execute_reply": "2024-04-13T07:58:53.509573Z"
        },
        "trusted": true,
        "id": "rU9jMd8WnhY-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNOgisHOE-8G",
        "outputId": "66bb2248-b0a0-48a6-e3df-984a6d1fb707"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29653, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "Ww_jY_NZP_hT",
        "outputId": "9e6a6701-ae35-4a58-bc9f-1b24b8388ffd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Question  \\\n",
              "0   the banker ' s gain of a certain sum due 3 yea...   \n",
              "1   average age of students of an adult school is ...   \n",
              "2   sophia finished 2 / 3 of a book . she calculat...   \n",
              "3                         120 is what percent of 50 ?   \n",
              "4   there are 10 girls and 20 boys in a classroom ...   \n",
              "5   an empty fuel tank with a capacity of 218 gall...   \n",
              "6   an article is bought for rs . 823 and sold for...   \n",
              "7   6 workers should finish a job in 8 days . afte...   \n",
              "8   j is 25 % less than p and 20 % less than t . t...   \n",
              "9   a student was asked to find 4 / 5 of a number ...   \n",
              "10  the average weight of 8 person ' s increases b...   \n",
              "11  a train 125 m long passes a man , running at 1...   \n",
              "12  the average of 15 result is 60 . average of th...   \n",
              "13  a salesman â € ™ s terms were changed from a f...   \n",
              "14  a rectangular floor that measures 15 meters by...   \n",
              "15  a vessel of capacity 2 litre has 30 % of alcoh...   \n",
              "16  the total of 324 of 20 paise and 25 paise make...   \n",
              "17  in 1970 there were 8,902 women stockbrokers in...   \n",
              "18  what is the number of integers from 1 to 1100 ...   \n",
              "19  arun makes a popular brand of ice cream in a r...   \n",
              "\n",
              "                                            Equation  \n",
              "0                 x=((100*((36*100)/(3*10)))/(3*10))  \n",
              "1        x=(((((32+4)*120)-(120*32))/(40-(32+4)))*4)  \n",
              "2                                   x=(90/(1-(2/3)))  \n",
              "3                                   x=((120/50)*100)  \n",
              "4                                          x=(10/20)  \n",
              "5        x=(((218*(16/100))-30)/((16/100)-(12/100)))  \n",
              "6                           x=(100-((1000*100)/823))  \n",
              "7                            x=(((6*8)-(3*6))/(6+4))  \n",
              "8                                    x=((25*25)/100)  \n",
              "9   x=((((36*(4/5))*(4/5))/(1-((4/5)*(4/5))))/(4/5))  \n",
              "10                                    x=((8*1.5)+75)  \n",
              "11            x=(((125-((15*0.2778)*15))/15)/0.2778)  \n",
              "12                     x=(((10*10)+(10*80))-(15*60))  \n",
              "13                                      x=((5*4)-12)  \n",
              "14                                         x=(15*15)  \n",
              "15          x=(((((30/100)*2)+((40/100)*6))/10)*100)  \n",
              "16                   x=(((324*25)-(70*100))/(25-20))  \n",
              "17                                    x=((18-947)/8)  \n",
              "18   x=(1100-(((1100/11)+(1100/35))-(1100/(11*35))))  \n",
              "19                               x=((((6*5)*2)/2)+3)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd036b18-3f04-4a36-a6b4-a3eeb16d5041\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Equation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the banker ' s gain of a certain sum due 3 yea...</td>\n",
              "      <td>x=((100*((36*100)/(3*10)))/(3*10))</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>average age of students of an adult school is ...</td>\n",
              "      <td>x=(((((32+4)*120)-(120*32))/(40-(32+4)))*4)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sophia finished 2 / 3 of a book . she calculat...</td>\n",
              "      <td>x=(90/(1-(2/3)))</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>120 is what percent of 50 ?</td>\n",
              "      <td>x=((120/50)*100)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>there are 10 girls and 20 boys in a classroom ...</td>\n",
              "      <td>x=(10/20)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>an empty fuel tank with a capacity of 218 gall...</td>\n",
              "      <td>x=(((218*(16/100))-30)/((16/100)-(12/100)))</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>an article is bought for rs . 823 and sold for...</td>\n",
              "      <td>x=(100-((1000*100)/823))</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6 workers should finish a job in 8 days . afte...</td>\n",
              "      <td>x=(((6*8)-(3*6))/(6+4))</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>j is 25 % less than p and 20 % less than t . t...</td>\n",
              "      <td>x=((25*25)/100)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>a student was asked to find 4 / 5 of a number ...</td>\n",
              "      <td>x=((((36*(4/5))*(4/5))/(1-((4/5)*(4/5))))/(4/5))</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>the average weight of 8 person ' s increases b...</td>\n",
              "      <td>x=((8*1.5)+75)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>a train 125 m long passes a man , running at 1...</td>\n",
              "      <td>x=(((125-((15*0.2778)*15))/15)/0.2778)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>the average of 15 result is 60 . average of th...</td>\n",
              "      <td>x=(((10*10)+(10*80))-(15*60))</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>a salesman â € ™ s terms were changed from a f...</td>\n",
              "      <td>x=((5*4)-12)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>a rectangular floor that measures 15 meters by...</td>\n",
              "      <td>x=(15*15)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>a vessel of capacity 2 litre has 30 % of alcoh...</td>\n",
              "      <td>x=(((((30/100)*2)+((40/100)*6))/10)*100)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>the total of 324 of 20 paise and 25 paise make...</td>\n",
              "      <td>x=(((324*25)-(70*100))/(25-20))</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>in 1970 there were 8,902 women stockbrokers in...</td>\n",
              "      <td>x=((18-947)/8)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>what is the number of integers from 1 to 1100 ...</td>\n",
              "      <td>x=(1100-(((1100/11)+(1100/35))-(1100/(11*35))))</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>arun makes a popular brand of ice cream in a r...</td>\n",
              "      <td>x=((((6*5)*2)/2)+3)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd036b18-3f04-4a36-a6b4-a3eeb16d5041')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd036b18-3f04-4a36-a6b4-a3eeb16d5041 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd036b18-3f04-4a36-a6b4-a3eeb16d5041');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9ee8636c-a557-4538-a1f1-5d601bb7ac3b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9ee8636c-a557-4538-a1f1-5d601bb7ac3b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9ee8636c-a557-4538-a1f1-5d601bb7ac3b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 29653,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29653,\n        \"samples\": [\n          \"if 5 machines can produce 20 units in 10 hours , how long would it take 20 machines to produce 160 units ?\",\n          \"there are 76 persons . 54 can read hindu , 43 can read times , 37 can read deccan and 15 can read all . if 24 can read hindu and deccan and 27 can read deccan and times then what is the number of persons who read only times and hindu .\",\n          \"if x is less than y by 25 % then y exceed x by :\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Equation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25372,\n        \"samples\": [\n          \"x=((((6*3)+22)*(((6*3)+22)/5))+6)\",\n          \"x=(10111-((10*2)*5))\",\n          \"x=((175*100)/(100-((100-25)+((100-25)*(10/100)))))\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = list(df['Question'].values)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T07:59:14.011074Z",
          "iopub.execute_input": "2024-04-13T07:59:14.011552Z",
          "iopub.status.idle": "2024-04-13T07:59:14.024444Z",
          "shell.execute_reply.started": "2024-04-13T07:59:14.011513Z",
          "shell.execute_reply": "2024-04-13T07:59:14.023137Z"
        },
        "trusted": true,
        "id": "OOxcDmAHnhY_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spacify(s):\n",
        "    return ' '.join(list(s))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T07:59:15.953544Z",
          "iopub.execute_input": "2024-04-13T07:59:15.953991Z",
          "iopub.status.idle": "2024-04-13T07:59:15.960133Z",
          "shell.execute_reply.started": "2024-04-13T07:59:15.953955Z",
          "shell.execute_reply": "2024-04-13T07:59:15.958767Z"
        },
        "trusted": true,
        "id": "ZYUQYguNnhY_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = list(df['Equation'].apply(lambda y: spacify(y)).values)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T07:59:19.780463Z",
          "iopub.execute_input": "2024-04-13T07:59:19.780888Z",
          "iopub.status.idle": "2024-04-13T07:59:19.856698Z",
          "shell.execute_reply.started": "2024-04-13T07:59:19.780855Z",
          "shell.execute_reply": "2024-04-13T07:59:19.855603Z"
        },
        "trusted": true,
        "id": "a-Thw55RnhZA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCcpB0MQQJeq",
        "outputId": "8ef3131e-ab96-4eb1-f9a4-7892809ff833"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"the banker ' s gain of a certain sum due 3 years hence at 10 % per annum is rs . 36 . what is the present worth ?\",\n",
              " 'average age of students of an adult school is 40 years . 120 new students whose average age is 32 years joined the school . as a result the average age is decreased by 4 years . find the number of students of the school after joining of the new students .',\n",
              " 'sophia finished 2 / 3 of a book . she calculated that she finished 90 more pages than she has yet to read . how long is her book ?',\n",
              " '120 is what percent of 50 ?',\n",
              " 'there are 10 girls and 20 boys in a classroom . what is the ratio of girls to boys ?',\n",
              " 'an empty fuel tank with a capacity of 218 gallons was filled partially with fuel a and then to capacity with fuel b . fuel a contains 12 % ethanol by volume and fuel b contains 16 % ethanol by volume . if the full fuel tank contains 30 gallons of ethanol , how many gallons of fuel a were added ?',\n",
              " 'an article is bought for rs . 823 and sold for rs . 1000 , find the gain percent ?',\n",
              " '6 workers should finish a job in 8 days . after 3 days came 4 workers join them . how many days m do they need to finish the same job ?',\n",
              " 'j is 25 % less than p and 20 % less than t . t is q % less than p . what is the value of q ?',\n",
              " 'a student was asked to find 4 / 5 of a number . but the student divided the number by 4 / 5 , thus the student got 36 more than the correct answer . find the number .']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y[:10]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T07:59:21.986030Z",
          "iopub.execute_input": "2024-04-13T07:59:21.987226Z",
          "iopub.status.idle": "2024-04-13T07:59:21.995517Z",
          "shell.execute_reply.started": "2024-04-13T07:59:21.987162Z",
          "shell.execute_reply": "2024-04-13T07:59:21.994253Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNOKOghdnhZA",
        "outputId": "01e9df39-3f29-4d5b-d794-392d6be59824"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['x = ( ( 1 0 0 * ( ( 3 6 * 1 0 0 ) / ( 3 * 1 0 ) ) ) / ( 3 * 1 0 ) )',\n",
              " 'x = ( ( ( ( ( 3 2 + 4 ) * 1 2 0 ) - ( 1 2 0 * 3 2 ) ) / ( 4 0 - ( 3 2 + 4 ) ) ) * 4 )',\n",
              " 'x = ( 9 0 / ( 1 - ( 2 / 3 ) ) )',\n",
              " 'x = ( ( 1 2 0 / 5 0 ) * 1 0 0 )',\n",
              " 'x = ( 1 0 / 2 0 )',\n",
              " 'x = ( ( ( 2 1 8 * ( 1 6 / 1 0 0 ) ) - 3 0 ) / ( ( 1 6 / 1 0 0 ) - ( 1 2 / 1 0 0 ) ) )',\n",
              " 'x = ( 1 0 0 - ( ( 1 0 0 0 * 1 0 0 ) / 8 2 3 ) )',\n",
              " 'x = ( ( ( 6 * 8 ) - ( 3 * 6 ) ) / ( 6 + 4 ) )',\n",
              " 'x = ( ( 2 5 * 2 5 ) / 1 0 0 )',\n",
              " 'x = ( ( ( ( 3 6 * ( 4 / 5 ) ) * ( 4 / 5 ) ) / ( 1 - ( ( 4 / 5 ) * ( 4 / 5 ) ) ) ) / ( 4 / 5 ) )']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_X(s):\n",
        "    s = s.lower().strip()\n",
        "    s = re.sub(r\"([?.!,’])\", r\" \\1 \", s)\n",
        "    s = re.sub(r\"([0-9])\", r\" \\1 \", s)\n",
        "    s = re.sub(r'[\" \"]+', \" \", s)\n",
        "    s = s.rstrip().strip()\n",
        "    return s\n",
        "\n",
        "def preprocess_Y(e):\n",
        "    e = e.lower().strip()\n",
        "    return e"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T07:59:33.946739Z",
          "iopub.execute_input": "2024-04-13T07:59:33.947253Z",
          "iopub.status.idle": "2024-04-13T07:59:33.954958Z",
          "shell.execute_reply.started": "2024-04-13T07:59:33.947217Z",
          "shell.execute_reply": "2024-04-13T07:59:33.953660Z"
        },
        "trusted": true,
        "id": "smIoZU-VnhZA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_pp = list(map(preprocess_X, X))\n",
        "Y_pp = list(map(preprocess_Y, Y))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T07:59:36.568676Z",
          "iopub.execute_input": "2024-04-13T07:59:36.569635Z",
          "iopub.status.idle": "2024-04-13T07:59:38.457696Z",
          "shell.execute_reply.started": "2024-04-13T07:59:36.569592Z",
          "shell.execute_reply": "2024-04-13T07:59:38.456529Z"
        },
        "trusted": true,
        "id": "4Are-hbznhZB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_pp[:10]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T07:59:38.459893Z",
          "iopub.execute_input": "2024-04-13T07:59:38.460342Z",
          "iopub.status.idle": "2024-04-13T07:59:38.468995Z",
          "shell.execute_reply.started": "2024-04-13T07:59:38.460302Z",
          "shell.execute_reply": "2024-04-13T07:59:38.467404Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsWfi9vjnhZB",
        "outputId": "e16c7153-9e46-4794-8bbf-485e6819fbaf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"the banker ' s gain of a certain sum due 3 years hence at 1 0 % per annum is rs . 3 6 . what is the present worth ?\",\n",
              " 'average age of students of an adult school is 4 0 years . 1 2 0 new students whose average age is 3 2 years joined the school . as a result the average age is decreased by 4 years . find the number of students of the school after joining of the new students .',\n",
              " 'sophia finished 2 / 3 of a book . she calculated that she finished 9 0 more pages than she has yet to read . how long is her book ?',\n",
              " '1 2 0 is what percent of 5 0 ?',\n",
              " 'there are 1 0 girls and 2 0 boys in a classroom . what is the ratio of girls to boys ?',\n",
              " 'an empty fuel tank with a capacity of 2 1 8 gallons was filled partially with fuel a and then to capacity with fuel b . fuel a contains 1 2 % ethanol by volume and fuel b contains 1 6 % ethanol by volume . if the full fuel tank contains 3 0 gallons of ethanol , how many gallons of fuel a were added ?',\n",
              " 'an article is bought for rs . 8 2 3 and sold for rs . 1 0 0 0 , find the gain percent ?',\n",
              " '6 workers should finish a job in 8 days . after 3 days came 4 workers join them . how many days m do they need to finish the same job ?',\n",
              " 'j is 2 5 % less than p and 2 0 % less than t . t is q % less than p . what is the value of q ?',\n",
              " 'a student was asked to find 4 / 5 of a number . but the student divided the number by 4 / 5 , thus the student got 3 6 more than the correct answer . find the number .']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pp[:10]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T07:59:40.993877Z",
          "iopub.execute_input": "2024-04-13T07:59:40.994324Z",
          "iopub.status.idle": "2024-04-13T07:59:41.002592Z",
          "shell.execute_reply.started": "2024-04-13T07:59:40.994291Z",
          "shell.execute_reply": "2024-04-13T07:59:41.000986Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYVM9xNknhZC",
        "outputId": "41fc5cfb-c8d6-412e-9b78-4ca1e005bda0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['x = ( ( 1 0 0 * ( ( 3 6 * 1 0 0 ) / ( 3 * 1 0 ) ) ) / ( 3 * 1 0 ) )',\n",
              " 'x = ( ( ( ( ( 3 2 + 4 ) * 1 2 0 ) - ( 1 2 0 * 3 2 ) ) / ( 4 0 - ( 3 2 + 4 ) ) ) * 4 )',\n",
              " 'x = ( 9 0 / ( 1 - ( 2 / 3 ) ) )',\n",
              " 'x = ( ( 1 2 0 / 5 0 ) * 1 0 0 )',\n",
              " 'x = ( 1 0 / 2 0 )',\n",
              " 'x = ( ( ( 2 1 8 * ( 1 6 / 1 0 0 ) ) - 3 0 ) / ( ( 1 6 / 1 0 0 ) - ( 1 2 / 1 0 0 ) ) )',\n",
              " 'x = ( 1 0 0 - ( ( 1 0 0 0 * 1 0 0 ) / 8 2 3 ) )',\n",
              " 'x = ( ( ( 6 * 8 ) - ( 3 * 6 ) ) / ( 6 + 4 ) )',\n",
              " 'x = ( ( 2 5 * 2 5 ) / 1 0 0 )',\n",
              " 'x = ( ( ( ( 3 6 * ( 4 / 5 ) ) * ( 4 / 5 ) ) / ( 1 - ( ( 4 / 5 ) * ( 4 / 5 ) ) ) ) / ( 4 / 5 ) )']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(lang):\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    return tensor, lang_tokenizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T07:59:43.157559Z",
          "iopub.execute_input": "2024-04-13T07:59:43.157962Z",
          "iopub.status.idle": "2024-04-13T07:59:43.164922Z",
          "shell.execute_reply.started": "2024-04-13T07:59:43.157931Z",
          "shell.execute_reply": "2024-04-13T07:59:43.163490Z"
        },
        "trusted": true,
        "id": "FVliMfrgnhZC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor, X_lang_tokenizer = tokenize(X_pp)\n",
        "len(X_lang_tokenizer.word_index)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T07:59:46.889485Z",
          "iopub.execute_input": "2024-04-13T07:59:46.889887Z",
          "iopub.status.idle": "2024-04-13T07:59:49.113139Z",
          "shell.execute_reply.started": "2024-04-13T07:59:46.889854Z",
          "shell.execute_reply": "2024-04-13T07:59:49.111954Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb0J8npnnhZD",
        "outputId": "cc386f00-0725-4cd0-c271-ead57e0173f5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7692"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_tensor, Y_lang_tokenizer = tokenize(Y_pp)\n",
        "len(Y_lang_tokenizer.word_index)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T07:59:49.115738Z",
          "iopub.execute_input": "2024-04-13T07:59:49.116212Z",
          "iopub.status.idle": "2024-04-13T07:59:50.202331Z",
          "shell.execute_reply.started": "2024-04-13T07:59:49.116157Z",
          "shell.execute_reply": "2024-04-13T07:59:50.200824Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5tD4kuTnhZD",
        "outputId": "754b7c07-cb4a-46d8-b697-8b1d4eb2e2bf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previous_length = len(Y_lang_tokenizer.word_index)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T07:59:50.203878Z",
          "iopub.execute_input": "2024-04-13T07:59:50.204306Z",
          "iopub.status.idle": "2024-04-13T07:59:50.209989Z",
          "shell.execute_reply.started": "2024-04-13T07:59:50.204271Z",
          "shell.execute_reply": "2024-04-13T07:59:50.208679Z"
        },
        "trusted": true,
        "id": "RaepAj47nhZD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add integers for < start > and < end > tokens for input problems and target math expressions."
      ],
      "metadata": {
        "id": "-9OsjoJvnhZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def append_head_tail(x, last_int):\n",
        "    l = []\n",
        "    l.append(last_int + 1)\n",
        "    l.extend(x)\n",
        "    l.append(last_int + 2)\n",
        "    return l"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T07:59:53.120712Z",
          "iopub.execute_input": "2024-04-13T07:59:53.121138Z",
          "iopub.status.idle": "2024-04-13T07:59:53.129159Z",
          "shell.execute_reply.started": "2024-04-13T07:59:53.121104Z",
          "shell.execute_reply": "2024-04-13T07:59:53.127774Z"
        },
        "trusted": true,
        "id": "d7Gic214nhZF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor_list = [append_head_tail(i, len(X_lang_tokenizer.word_index)) for i in X_tensor]\n",
        "Y_tensor_list = [append_head_tail(i, len(Y_lang_tokenizer.word_index)) for i in Y_tensor]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:00:01.098223Z",
          "iopub.execute_input": "2024-04-13T08:00:01.098668Z",
          "iopub.status.idle": "2024-04-13T08:00:01.216697Z",
          "shell.execute_reply.started": "2024-04-13T08:00:01.098632Z",
          "shell.execute_reply": "2024-04-13T08:00:01.215345Z"
        },
        "trusted": true,
        "id": "79lfHz1QnhZG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding the sequences with 0's to make them equal in length."
      ],
      "metadata": {
        "id": "Oy9jKspAnhZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor = tf.keras.preprocessing.sequence.pad_sequences(X_tensor_list, padding='post')\n",
        "Y_tensor = tf.keras.preprocessing.sequence.pad_sequences(Y_tensor_list, padding='post')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:00:04.948618Z",
          "iopub.execute_input": "2024-04-13T08:00:04.949827Z",
          "iopub.status.idle": "2024-04-13T08:00:05.991527Z",
          "shell.execute_reply.started": "2024-04-13T08:00:04.949776Z",
          "shell.execute_reply": "2024-04-13T08:00:05.990226Z"
        },
        "trusted": true,
        "id": "_MuOyQDdnhZH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:00:09.575364Z",
          "iopub.execute_input": "2024-04-13T08:00:09.575804Z",
          "iopub.status.idle": "2024-04-13T08:00:09.584571Z",
          "shell.execute_reply.started": "2024-04-13T08:00:09.575769Z",
          "shell.execute_reply": "2024-04-13T08:00:09.583094Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17b1bwB1nhZH",
        "outputId": "185977c2-2dff-439d-8d9a-31f9f08e2f33"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7693,    1, 1403, ...,    0,    0,    0],\n",
              "       [7693,   39,  110, ...,    0,    0,    0],\n",
              "       [7693, 5179,  859, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [7693,   23,   32, ...,    0,    0,    0],\n",
              "       [7693,   19,    1, ...,    0,    0,    0],\n",
              "       [7693,    1,   71, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_tensor"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:00:12.760659Z",
          "iopub.execute_input": "2024-04-13T08:00:12.761078Z",
          "iopub.status.idle": "2024-04-13T08:00:12.769496Z",
          "shell.execute_reply.started": "2024-04-13T08:00:12.761042Z",
          "shell.execute_reply": "2024-04-13T08:00:12.767975Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkRelCvznhZI",
        "outputId": "b0a49e94-1cba-4495-8dc2-5a8ad7c4ea8a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[20,  9, 10, ...,  0,  0,  0],\n",
              "       [20,  9, 10, ...,  0,  0,  0],\n",
              "       [20,  9, 10, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [20,  9, 10, ...,  0,  0,  0],\n",
              "       [20,  9, 10, ...,  0,  0,  0],\n",
              "       [20,  9, 10, ...,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Increasing the vocabulary size of the target by including some fodder words which won't be used. This is done to avoid problems later which manifest due to short vocabulary size."
      ],
      "metadata": {
        "id": "SoSxstzFnhZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keys = ['10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21',\n",
        "        '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33',\n",
        "        '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45',\n",
        "        '46', '47', '48', '49', '50']\n",
        "\n",
        "for idx,key in enumerate(keys):\n",
        "    Y_lang_tokenizer.word_index[key] = len(Y_lang_tokenizer.word_index) + idx + 4"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:05:33.350104Z",
          "iopub.execute_input": "2024-04-13T08:05:33.350649Z",
          "iopub.status.idle": "2024-04-13T08:05:33.358752Z",
          "shell.execute_reply.started": "2024-04-13T08:05:33.350607Z",
          "shell.execute_reply": "2024-04-13T08:05:33.357542Z"
        },
        "trusted": true,
        "id": "EOYgHDeinhZK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Y_lang_tokenizer.word_index)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:05:41.510868Z",
          "iopub.execute_input": "2024-04-13T08:05:41.511469Z",
          "iopub.status.idle": "2024-04-13T08:05:41.526540Z",
          "shell.execute_reply.started": "2024-04-13T08:05:41.511425Z",
          "shell.execute_reply": "2024-04-13T08:05:41.525265Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WsqysOunhZK",
        "outputId": "37f52818-71c9-41b6-fc71-3418e6e38b53"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train-Test Split → 95 : 5**"
      ],
      "metadata": {
        "id": "Zz69G2L2nhZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor_train, X_tensor_test, Y_tensor_train, Y_tensor_test = train_test_split(X_tensor, Y_tensor, test_size=0.05, random_state=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:06:48.302598Z",
          "iopub.execute_input": "2024-04-13T08:06:48.303017Z",
          "iopub.status.idle": "2024-04-13T08:06:48.738148Z",
          "shell.execute_reply.started": "2024-04-13T08:06:48.302984Z",
          "shell.execute_reply": "2024-04-13T08:06:48.737107Z"
        },
        "trusted": true,
        "id": "JFKrW8C3nhZL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_tensor_train), len(X_tensor_test), len(Y_tensor_train), len(Y_tensor_test))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:07:06.852023Z",
          "iopub.execute_input": "2024-04-13T08:07:06.852469Z",
          "iopub.status.idle": "2024-04-13T08:07:06.858561Z",
          "shell.execute_reply.started": "2024-04-13T08:07:06.852432Z",
          "shell.execute_reply": "2024-04-13T08:07:06.857333Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe0vFg3PnhZL",
        "outputId": "b08ca281-f750-4cf5-935d-557ee1becd60"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28170 1483 28170 1483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameters**"
      ],
      "metadata": {
        "id": "IbgxNfm9nhZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_SET_SIZE = len(X_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = np.floor(TRAINING_SET_SIZE/BATCH_SIZE)\n",
        "\n",
        "data = tf.data.Dataset.from_tensor_slices((X_tensor_train, Y_tensor_train)).shuffle(TRAINING_SET_SIZE)\n",
        "data = data.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "num_layers = 4\n",
        "d_model = 128       # Embedding dimension\n",
        "dff = 512           # Dimensionality of inner-layer of FNN\n",
        "num_heads = 8       # Number of parallel attention layers (heads)\n",
        "dropout_rate = 0\n",
        "\n",
        "X_vocabulary_size = len(X_lang_tokenizer.word_index) + 3\n",
        "Y_vocabulary_size = len(Y_lang_tokenizer.word_index) + 3"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:08:16.134455Z",
          "iopub.execute_input": "2024-04-13T08:08:16.134908Z",
          "iopub.status.idle": "2024-04-13T08:08:16.617823Z",
          "shell.execute_reply.started": "2024-04-13T08:08:16.134875Z",
          "shell.execute_reply": "2024-04-13T08:08:16.616507Z"
        },
        "trusted": true,
        "id": "KkPHOc3nnhZM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:08:28.421991Z",
          "iopub.execute_input": "2024-04-13T08:08:28.422914Z",
          "iopub.status.idle": "2024-04-13T08:08:28.429698Z",
          "shell.execute_reply.started": "2024-04-13T08:08:28.422870Z",
          "shell.execute_reply": "2024-04-13T08:08:28.428564Z"
        },
        "trusted": true,
        "id": "lmf_yseynhZN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:08:31.129781Z",
          "iopub.execute_input": "2024-04-13T08:08:31.130251Z",
          "iopub.status.idle": "2024-04-13T08:08:31.138314Z",
          "shell.execute_reply.started": "2024-04-13T08:08:31.130212Z",
          "shell.execute_reply": "2024-04-13T08:08:31.137060Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-PRmrPsnhZN",
        "outputId": "4294a609-5327-45fc-80ba-3d8982b6728c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 382), dtype=tf.int32, name=None), TensorSpec(shape=(64, 2543), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_batch_example, Y_batch_example = next(iter(data))\n",
        "\n",
        "print(X_batch_example, Y_batch_example)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:08:39.929677Z",
          "iopub.execute_input": "2024-04-13T08:08:39.930209Z",
          "iopub.status.idle": "2024-04-13T08:08:40.620594Z",
          "shell.execute_reply.started": "2024-04-13T08:08:39.930146Z",
          "shell.execute_reply": "2024-04-13T08:08:40.619427Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0sG6NpdnhZO",
        "outputId": "3753c3da-0202-448e-a24c-42281260b39c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[7693   47  319 ...    0    0    0]\n",
            " [7693    1  248 ...    0    0    0]\n",
            " [7693 4358 1795 ...    0    0    0]\n",
            " ...\n",
            " [7693   23   32 ...    0    0    0]\n",
            " [7693   13    5 ...    0    0    0]\n",
            " [7693   20    5 ...    0    0    0]], shape=(64, 382), dtype=int32) tf.Tensor(\n",
            "[[20  9 10 ...  0  0  0]\n",
            " [20  9 10 ...  0  0  0]\n",
            " [20  9 10 ...  0  0  0]\n",
            " ...\n",
            " [20  9 10 ...  0  0  0]\n",
            " [20  9 10 ...  0  0  0]\n",
            " [20  9 10 ...  0  0  0]], shape=(64, 2543), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positional Encoding**"
      ],
      "metadata": {
        "id": "-grM4FIynhZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:09:23.397517Z",
          "iopub.execute_input": "2024-04-13T08:09:23.397951Z",
          "iopub.status.idle": "2024-04-13T08:09:23.405224Z",
          "shell.execute_reply.started": "2024-04-13T08:09:23.397917Z",
          "shell.execute_reply": "2024-04-13T08:09:23.403744Z"
        },
        "trusted": true,
        "id": "YXWmccvFnhZO"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:09:32.167366Z",
          "iopub.execute_input": "2024-04-13T08:09:32.167791Z",
          "iopub.status.idle": "2024-04-13T08:09:32.175537Z",
          "shell.execute_reply.started": "2024-04-13T08:09:32.167760Z",
          "shell.execute_reply": "2024-04-13T08:09:32.174389Z"
        },
        "trusted": true,
        "id": "aqkJw-XznhZP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Masking**\n",
        "\n",
        "We mask all the padding elements so that they are not considered as input to the model. The position of the pad tokens are the positions at which the mask shows 1 and at the other locations it shows 0. The subsequent tokens in a sequence are masked using the look-ahead mask and this mask indicates the entries that should be avoided."
      ],
      "metadata": {
        "id": "E1c_TufPnhZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "    # add extra dimensions to add the padding\n",
        "    # to the attention logits.\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:10:47.216993Z",
          "iopub.execute_input": "2024-04-13T08:10:47.217466Z",
          "iopub.status.idle": "2024-04-13T08:10:47.224146Z",
          "shell.execute_reply.started": "2024-04-13T08:10:47.217436Z",
          "shell.execute_reply": "2024-04-13T08:10:47.222762Z"
        },
        "trusted": true,
        "id": "pcahkLxrnhZQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:10:56.451742Z",
          "iopub.execute_input": "2024-04-13T08:10:56.452154Z",
          "iopub.status.idle": "2024-04-13T08:10:56.458303Z",
          "shell.execute_reply.started": "2024-04-13T08:10:56.452120Z",
          "shell.execute_reply": "2024-04-13T08:10:56.456967Z"
        },
        "trusted": true,
        "id": "KQAHU4dNnhZQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scaled Dot-product Attention**\n",
        "\n",
        "A “soft” dictionary lookup which returns a weighted sum of the values in the corpus. This weight represents the usefulness of a particular token in embedding the query token. Then, it is scaled by dividing with sqrt(dk) inside softmax.\n"
      ],
      "metadata": {
        "id": "3wZj0GRMnhZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "    # add up to 1.\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:12:22.860479Z",
          "iopub.execute_input": "2024-04-13T08:12:22.861038Z",
          "iopub.status.idle": "2024-04-13T08:12:22.871265Z",
          "shell.execute_reply.started": "2024-04-13T08:12:22.860992Z",
          "shell.execute_reply": "2024-04-13T08:12:22.869798Z"
        },
        "trusted": true,
        "id": "sKNZ_CAfnhZg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multi-Head Attention**\n",
        "\n",
        "It is a combination of 'h' self-attention heads, where each head is sandwiched between two linear layers."
      ],
      "metadata": {
        "id": "ZXuTK63snhZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into (num_heads, depth).\n",
        "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention,\n",
        "                                    (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:13:37.990701Z",
          "iopub.execute_input": "2024-04-13T08:13:37.991257Z",
          "iopub.status.idle": "2024-04-13T08:13:38.006770Z",
          "shell.execute_reply.started": "2024-04-13T08:13:37.991219Z",
          "shell.execute_reply": "2024-04-13T08:13:38.005413Z"
        },
        "trusted": true,
        "id": "Fnmm9J_hnhZg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Point-wise Feed Forward Neural Network**\n",
        "\n",
        "Every encoder and decoder layer contains a fully connected feed-forward network. It is composed of two fully-connected layers with a ReLU activation function in between them.\n"
      ],
      "metadata": {
        "id": "URavCXuwnhZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "    ])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:14:23.546645Z",
          "iopub.execute_input": "2024-04-13T08:14:23.547146Z",
          "iopub.status.idle": "2024-04-13T08:14:23.554455Z",
          "shell.execute_reply.started": "2024-04-13T08:14:23.547108Z",
          "shell.execute_reply": "2024-04-13T08:14:23.553044Z"
        },
        "trusted": true,
        "id": "sS_x0DZknhZh"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder**\n",
        "\n",
        "The encoder consists of N layers and each layer has 2 sub-layers. The first sub-layer is a multi-head self attention mechanism layer and the second sub-layer is a position-wise fully connected feed-forward neural network. Each of these sub-layers is preceded by a skip connection or residual connection and succeeded by a layer normalization block. They result in outputs of dimension dmodel to facilitate the skip connections. The residual connections are important as they assist in overcoming the vanishing gradient problem in deep network architectures."
      ],
      "metadata": {
        "id": "QdXV9UbonhZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        # normalize data per feature instead of batch\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        # Multi-head attention layer\n",
        "        attn_output, _ = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        # add residual connection to avoid vanishing gradient problem\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        # Feedforward layer\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        # add residual connection to avoid vanishing gradient problem\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "        return out2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:15:18.493472Z",
          "iopub.execute_input": "2024-04-13T08:15:18.493892Z",
          "iopub.status.idle": "2024-04-13T08:15:18.505952Z",
          "shell.execute_reply.started": "2024-04-13T08:15:18.493861Z",
          "shell.execute_reply": "2024-04-13T08:15:18.504505Z"
        },
        "trusted": true,
        "id": "QDMU1jsynhZi"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "                maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                                self.d_model)\n",
        "\n",
        "        # Create encoder layers (count: num_layers)\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "                        for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        # adding embedding and position encoding.\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:15:31.220809Z",
          "iopub.execute_input": "2024-04-13T08:15:31.222257Z",
          "iopub.status.idle": "2024-04-13T08:15:31.239131Z",
          "shell.execute_reply.started": "2024-04-13T08:15:31.222187Z",
          "shell.execute_reply": "2024-04-13T08:15:31.237483Z"
        },
        "trusted": true,
        "id": "tWu_3BStnhZj"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decoder**\n",
        "\n",
        "The decoder consists of N layers and each layer has 3 sub-layers. Two of the sub-layers are the same as those of the encoder. The third sub-layer utilizes the outputs of the encoder stack and performs multi-head attention over them. Decoder feeds on two types of inputs which are, the outputs of the encoder and positionally encoded target output embeddings. And just like the encoder, decoder also has subsequent layer normalization blocks and incorporation of skip connections after and before each sub-layer respectively. The principal task of decoder is to predict token at position n by looking at all the preceding n-1 tokens using the look-ahead mask. The predicted sequence is then passed through a fully-connected neural network layer to generate the final math expression."
      ],
      "metadata": {
        "id": "2eCukr0ZnhZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.dff = dff\n",
        "        self.rate = rate\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]  # Get the sequence length of x\n",
        "\n",
        "        # Calculate attention weights for the first multi-head attention layer\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        # Calculate attention weights for the second multi-head attention layer\n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)\n",
        "\n",
        "        # Apply point-wise feed forward network\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:17:16.158153Z",
          "iopub.execute_input": "2024-04-13T08:17:16.158677Z",
          "iopub.status.idle": "2024-04-13T08:17:16.172462Z",
          "shell.execute_reply.started": "2024-04-13T08:17:16.158630Z",
          "shell.execute_reply": "2024-04-13T08:17:16.171238Z"
        },
        "trusted": true,
        "id": "7qD_YZTQnhZk"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "                maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        #self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "\n",
        "        # Create decoder layers (count: num_layers)\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                        for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training,\n",
        "            look_ahead_mask, padding_mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "\n",
        "        x += self.pos_encoding[:,:seq_len,:]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                                look_ahead_mask, padding_mask)\n",
        "\n",
        "        # store attenion weights, they can be used to visualize while translating\n",
        "        attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "        attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "        return x, attention_weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:17:43.179853Z",
          "iopub.execute_input": "2024-04-13T08:17:43.181133Z",
          "iopub.status.idle": "2024-04-13T08:17:43.194966Z",
          "shell.execute_reply.started": "2024-04-13T08:17:43.181084Z",
          "shell.execute_reply": "2024-04-13T08:17:43.193035Z"
        },
        "trusted": true,
        "id": "KzaBBngenhZl"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "                target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                            input_vocab_size, pe_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                            target_vocab_size, pe_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, inp, tar, training, enc_padding_mask,\n",
        "            look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "        # Pass the input to the encoder\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "\n",
        "        # Pass the encoder output to the decoder\n",
        "        dec_output, attention_weights = self.decoder(\n",
        "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        # Pass the decoder output to the last linear layer\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output, attention_weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:17:57.290339Z",
          "iopub.execute_input": "2024-04-13T08:17:57.290878Z",
          "iopub.status.idle": "2024-04-13T08:17:57.303213Z",
          "shell.execute_reply.started": "2024-04-13T08:17:57.290832Z",
          "shell.execute_reply": "2024-04-13T08:17:57.301865Z"
        },
        "trusted": true,
        "id": "_X2Afb_MnhZl"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = tf.cast(d_model, tf.float32)  # Cast d_model to tf.float32\n",
        "\n",
        "        self.warmup_steps = tf.cast(warmup_steps, tf.float32)  # Cast warmup_steps to tf.float32\n",
        "\n",
        "    def __call__(self, step):\n",
        "\n",
        "        step = tf.cast(step, tf.float32)  # Cast step to tf.float32\n",
        "\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:18:05.894714Z",
          "iopub.execute_input": "2024-04-13T08:18:05.895124Z",
          "iopub.status.idle": "2024-04-13T08:18:05.903848Z",
          "shell.execute_reply.started": "2024-04-13T08:18:05.895092Z",
          "shell.execute_reply": "2024-04-13T08:18:05.902274Z"
        },
        "trusted": true,
        "id": "GGaQyhLEnhZl"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer**\n",
        "\n",
        "We used Adam with a custom learning rate scheduler as our optimizer. The learning rate was set according to,\n",
        "\n",
        "lrate = ((dmodel)^(-0.5)).min(n^-0.5 , n.(w^-0.5))\n",
        "\n",
        "where, dmodel is the embedding dimension, n is the step number and w is the number of warm-up steps. Here, warm-up steps w simply insinuates that the learning rate rises linearly for the initial w training steps."
      ],
      "metadata": {
        "id": "U2e5k0BvnhZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "# Adam optimizer with a custom learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:21:52.753876Z",
          "iopub.execute_input": "2024-04-13T08:21:52.754510Z",
          "iopub.status.idle": "2024-04-13T08:21:52.767727Z",
          "shell.execute_reply.started": "2024-04-13T08:21:52.754472Z",
          "shell.execute_reply": "2024-04-13T08:21:52.766280Z"
        },
        "trusted": true,
        "id": "HwqbpsCpnhZm"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:22:02.957971Z",
          "iopub.execute_input": "2024-04-13T08:22:02.959100Z",
          "iopub.status.idle": "2024-04-13T08:22:02.964550Z",
          "shell.execute_reply.started": "2024-04-13T08:22:02.959051Z",
          "shell.execute_reply": "2024-04-13T08:22:02.963285Z"
        },
        "trusted": true,
        "id": "8Pe81xeunhZn"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Metric**\n",
        "\n",
        "As output sequences are padded, it is important to apply a padding mask when calculating the loss. We used Sparse Categorical Cross-entropy for loss and Mean for accuracy. In the test-phase we also calcuated the BLEU (BiLingual Evaluation Understudy) score of our model to assess its translation quality."
      ],
      "metadata": {
        "id": "aIUzTfnunhZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(real, pred):\n",
        "    # Apply a mask to paddings (0)\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    accuracies = tf.equal(tf.cast(real, dtype=tf.int32), tf.cast(tf.argmax(pred, axis=2), dtype=tf.int32))\n",
        "\n",
        "    mask = tf.math.logical_not(tf.math.equal(tf.cast(real, dtype=tf.int32), 0))\n",
        "    accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:22:51.368305Z",
          "iopub.execute_input": "2024-04-13T08:22:51.368720Z",
          "iopub.status.idle": "2024-04-13T08:22:51.380108Z",
          "shell.execute_reply.started": "2024-04-13T08:22:51.368690Z",
          "shell.execute_reply": "2024-04-13T08:22:51.378421Z"
        },
        "trusted": true,
        "id": "9RAic4HWnhZo"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "train_accuracy_mean = tf.keras.metrics.Mean(name='train_accuracy_mean')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:22:59.421373Z",
          "iopub.execute_input": "2024-04-13T08:22:59.421851Z",
          "iopub.status.idle": "2024-04-13T08:22:59.445223Z",
          "shell.execute_reply.started": "2024-04-13T08:22:59.421811Z",
          "shell.execute_reply": "2024-04-13T08:22:59.443812Z"
        },
        "trusted": true,
        "id": "pkP1MLbmnhZo"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          X_vocabulary_size, Y_vocabulary_size,\n",
        "                          pe_input=X_vocabulary_size,\n",
        "                          pe_target=Y_vocabulary_size,\n",
        "                          rate=dropout_rate)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:23:12.976636Z",
          "iopub.execute_input": "2024-04-13T08:23:12.977277Z",
          "iopub.status.idle": "2024-04-13T08:23:13.178026Z",
          "shell.execute_reply.started": "2024-04-13T08:23:12.977241Z",
          "shell.execute_reply": "2024-04-13T08:23:13.176385Z"
        },
        "trusted": true,
        "id": "NWIRRJw7nhZo"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_masks(inp, tar):\n",
        "    # Encoder padding mask (Used in the 2nd attention block in the decoder too.)\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 1st attention block in the decoder.\n",
        "    # It is used to pad and mask future tokens in the input received by\n",
        "    # the decoder.\n",
        "    # Look ahead mask (for hiding the rest of the sequence in the 1st decoder attention layer)\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, look_ahead_mask, dec_padding_mask"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-13T08:23:29.353354Z",
          "iopub.execute_input": "2024-04-13T08:23:29.353789Z",
          "iopub.status.idle": "2024-04-13T08:23:29.361190Z",
          "shell.execute_reply.started": "2024-04-13T08:23:29.353753Z",
          "shell.execute_reply": "2024-04-13T08:23:29.359729Z"
        },
        "trusted": true,
        "id": "WZK0jeVInhZp"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "tE_DoBKDvE-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 17"
      ],
      "metadata": {
        "id": "PH0jcLpzuRwk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(inp, tar_inp,\n",
        "                                    True,\n",
        "                                    enc_padding_mask,\n",
        "                                    look_ahead_mask,\n",
        "                                    dec_padding_mask)\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(tar_real, predictions)\n",
        "    train_accuracy_mean(accuracy_function(tar_real, predictions))"
      ],
      "metadata": {
        "id": "ZVF-32sSvLP6"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    train_accuracy_mean.reset_states()\n",
        "\n",
        "    # inp -> math problem, tar -> expression\n",
        "    for (batch, (inp, tar)) in enumerate(data):\n",
        "        train_step(inp, tar)\n",
        "\n",
        "        if batch % 50 == 0:\n",
        "            print (f'Epoch {epoch + 1}, Batch {batch}, Loss {train_loss.result():.5f},\\\n",
        "             SC Accuracy {train_accuracy.result():.5f}, Mean Accuracy {train_accuracy_mean.result():.5f}')\n",
        "\n",
        "    print (f'Epoch {epoch + 1}, Loss {train_loss.result():.5f},\\\n",
        "     SC Accuracy {train_accuracy.result():.5f}, Mean Accuracy {train_accuracy_mean.result():.5f}')\n",
        "\n",
        "    print (f'Training time for this epoch: {(time.time() - start):.5f} seconds\\n')"
      ],
      "metadata": {
        "id": "yOD2M7RqvNtI"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 40"
      ],
      "metadata": {
        "id": "jkvmMLR_vdkD"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(input_problem):\n",
        "    start_token = [len(X_lang_tokenizer.word_index)+1]\n",
        "    end_token = [len(X_lang_tokenizer.word_index)+2]\n",
        "\n",
        "    # input_problem is the word problem, hence adding the start and end token\n",
        "    input_problem = start_token + [X_lang_tokenizer.word_index[i] for i in preprocess_X(input_problem).split(' ')] + end_token\n",
        "    encoder_input = tf.expand_dims(input_problem, 0)\n",
        "\n",
        "    # start with expression's start token\n",
        "    decoder_input = [previous_length+1]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "\n",
        "    for i in range(MAX_LENGTH):\n",
        "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "\n",
        "        predictions, attention_weights = transformer(encoder_input,\n",
        "                                                    output,\n",
        "                                                    False,\n",
        "                                                    enc_padding_mask,\n",
        "                                                    look_ahead_mask,\n",
        "                                                    dec_padding_mask)\n",
        "\n",
        "        # select the last word from the seq_len dimension\n",
        "        predictions = predictions[: ,-1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), dtype=tf.int32)\n",
        "\n",
        "        # return the result if the predicted_id is equal to the end token\n",
        "        if predicted_id == previous_length + 2:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "        # concatenate the predicted_id to the output which is given to the decoder\n",
        "        # as its input.\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "    return tf.squeeze(output, axis=0), attention_weights"
      ],
      "metadata": {
        "id": "XVyaBdmrvoHP"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_attention_weights(attention, problem, result, layer):\n",
        "    fig = plt.figure(figsize=(8, 16))\n",
        "\n",
        "    sentence = preprocess_X(problem)\n",
        "\n",
        "    attention = tf.squeeze(attention[layer], axis=0)\n",
        "\n",
        "    for head in range(attention.shape[0]):\n",
        "        ax = fig.add_subplot(4, 2, head+1)\n",
        "\n",
        "        # plot the attention weights\n",
        "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
        "\n",
        "        fontdict = {'fontsize': 11}\n",
        "\n",
        "        ax.set_xticks(range(len(sentence.split(' '))+2))\n",
        "        ax.set_yticks(range(len([Y_lang_tokenizer.index_word[i] for i in list(result.numpy())\n",
        "                            if i < len(Y_lang_tokenizer.word_index) and i not in [0,previous_length+1,previous_length+2]])+3))\n",
        "\n",
        "\n",
        "        ax.set_ylim(len([Y_lang_tokenizer.index_word[i] for i in list(result.numpy())\n",
        "                            if i < len(Y_lang_tokenizer.word_index) and i not in [0,previous_length+1,previous_length+2]]), -0.5)\n",
        "\n",
        "        ax.set_xticklabels(\n",
        "            ['<start>']+sentence.split(' ')+['<end>'],\n",
        "            fontdict=fontdict, rotation=90)\n",
        "\n",
        "        ax.set_yticklabels([Y_lang_tokenizer.index_word[i] for i in list(result.numpy())\n",
        "                            if i < len(Y_lang_tokenizer.word_index) and i not in [0,previous_length+1,previous_length+2]],\n",
        "                        fontdict=fontdict)\n",
        "\n",
        "        ax.set_xlabel(f'Head {head+1}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OkQD4VlEvyyH"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve(problem, plot='', plot_Attention_Weights=False):\n",
        "    prediction, attention_weights = evaluate(problem)\n",
        "    predicted_expression = [Y_lang_tokenizer.index_word[i] \\\n",
        "                          for i in list(prediction.numpy()) \\\n",
        "                          if (i < len(Y_lang_tokenizer.word_index) and i not in [0,46,47])]\n",
        "    print(f'Input: {problem}')\n",
        "    print('Predicted translation: {}'.format(' '.join(predicted_expression)))\n",
        "\n",
        "    if plot_Attention_Weights:\n",
        "        plot_attention_weights(attention_weights, problem, prediction, plot)"
      ],
      "metadata": {
        "id": "zpJ4jaWnv2Sp"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_testset(input_problem):\n",
        "    start_token = [len(X_lang_tokenizer.word_index)+1]\n",
        "    end_token = [len(X_lang_tokenizer.word_index)+2]\n",
        "\n",
        "    # input_problem is the word problem, hence adding the start and end token\n",
        "    input_problem = start_token + list(input_problem.numpy()[0]) + end_token\n",
        "    encoder_input = tf.expand_dims(input_problem, 0)\n",
        "\n",
        "    # start with expression's start token\n",
        "    decoder_input = [previous_length+1]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "\n",
        "    for i in range(MAX_LENGTH):\n",
        "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "\n",
        "        predictions, attention_weights = transformer(encoder_input,\n",
        "                                                    output,\n",
        "                                                    False,\n",
        "                                                    enc_padding_mask,\n",
        "                                                    look_ahead_mask,\n",
        "                                                    dec_padding_mask)\n",
        "\n",
        "        # select the last word from the seq_len dimension\n",
        "        predictions = predictions[: ,-1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), dtype=tf.int32)\n",
        "\n",
        "        # return the result if the predicted_id is equal to the end token\n",
        "        if predicted_id == previous_length + 2:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "        # concatenate the predicted_id to the output which is given to the decoder\n",
        "        # as its input.\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "    return tf.squeeze(output, axis=0), attention_weights"
      ],
      "metadata": {
        "id": "2EOzVm_gv401"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = tf.data.Dataset.from_tensor_slices((X_tensor_test, Y_tensor_test)).shuffle(len(X_tensor_test))\n",
        "data_test = data_test.batch(1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "SfETRNLqv8E6"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_true = []\n",
        "Y_pred = []\n",
        "correctCount = 0\n",
        "\n",
        "idx = 0\n",
        "for(X_test_batch, Y_test_batch) in iter(data_test):\n",
        "    idx += 1\n",
        "    if idx % 10 == 0:\n",
        "        print(f'Samples tested: {idx}, Correctly solved: {correctCount}')\n",
        "    ground_truth_expression = ''\n",
        "    for i in Y_test_batch.numpy()[0]:\n",
        "        if i not in [0, previous_length + 1, previous_length + 2]:\n",
        "            ground_truth_expression += (Y_lang_tokenizer.index_word[i] + ' ')\n",
        "\n",
        "    Y_true.append([ground_truth_expression.split(' ')[:-1]])\n",
        "\n",
        "    prediction, attention_weights = evaluate_testset(X_test_batch)\n",
        "    predicted_expression = [Y_lang_tokenizer.index_word[i] \\\n",
        "                            for i in list(prediction.numpy()) \\\n",
        "                            if (i < len(Y_lang_tokenizer.word_index) and i not in [0, previous_length + 1, previous_length + 2])]\n",
        "    Y_pred.append(predicted_expression)\n",
        "    if ground_truth_expression.split(' ')[:-1] == predicted_expression:\n",
        "        correctCount += 1"
      ],
      "metadata": {
        "id": "GVG-N6ilv-DA"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Sl3A7Mc6gF2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}